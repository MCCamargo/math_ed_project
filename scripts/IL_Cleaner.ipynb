{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3920cb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "97e8ed21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge():\n",
    "    #This function takes data from across the different Illinois raw data sources and combines them into a single csv file, for each year.\n",
    "    for yr in range(19,24):\n",
    "        docstring = \"~/Documents/Erdos/Proj/math_ed_project/data/IL\" +str(yr) + \"/IL\" +str(yr) +\"RawData.xlsx\"\n",
    "        outstring = \"~/Documents/Erdos/Proj/math_ed_project/data/IL\" +str(yr) + \"/IL\" +str(yr) +\"_Combined_Ed_Demographic.csv\"\n",
    "\n",
    "        df1, df2, df3 = pd.read_excel(docstring, sheet_name=[\"General\", \"Financial\", \"SAT\"]).values()\n",
    "\n",
    "        df1dis = df1[df1[\"Type\" ]== \"District\"]\n",
    "        if yr != 23:\n",
    "            df1 = df1[df1[\"School Type\"].isin([\"HIGH SCHOOL\", \"CHARTER SCH\"])]\n",
    "        else:\n",
    "            df1 = df1[df1[\"School Type\"].isin([\"High School\", \"Middle/Junior High School\"])]\n",
    "        df1 = df1[df1[\"Type\"] == \"School\"]\n",
    "\n",
    "        # Step 1: Merge df1 with df1dis on \"District Name\"\n",
    "        merged = df1.merge(\n",
    "            df1dis,\n",
    "            on=\"District\",\n",
    "            suffixes=(\"\", \"_df1dis\"),\n",
    "            how=\"left\"\n",
    "        )\n",
    "\n",
    "        # Step 2: For each column in df1, fill in missing values using the value from df1dis. This is filling in missing school level data with corresponding district level data\n",
    "        for col in df1.columns:\n",
    "            if col != \"District\":  # Skip the join key\n",
    "                col_df1dis = col + \"_df1dis\"\n",
    "                if col_df1dis in merged.columns:\n",
    "                    merged[col] = merged[col].fillna(merged[col_df1dis])\n",
    "\n",
    "        # Step 3: Drop the extra _df1dis columns to clean up\n",
    "        df1 = merged[df1.columns]\n",
    "        del merged\n",
    "\n",
    "\n",
    "\n",
    "        common_cols1 = set(df1.columns) & set(df2.columns) - {\"RCDTS\"}\n",
    "        common_cols2 = set(df1.columns) & set(df3.columns) - {\"RCDTS\"}\n",
    "        df2 = df2.drop(columns=common_cols1)\n",
    "        df3 = df3.drop(columns=common_cols2)\n",
    "\n",
    "        df1 = df1.merge(df2,on=\"RCDTS\",how=\"inner\")\n",
    "        df1 = df1.merge(df3, on = \"RCDTS\", how = \"inner\")\n",
    "        df1[\"Year\"] = \"20\" + str(yr)\n",
    "        \n",
    "\n",
    "        df1.to_csv(outstring,index=False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c2016349",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def instr(n):\n",
    "        #Address each finle by year, with in-string\n",
    "        return \"~/Documents/Erdos/Proj/math_ed_project/data/IL\" +str(n) +\"/IL\" +str(n) +\"_Combined_Ed_Demographic.csv\"\n",
    "\n",
    "def cleaner():\n",
    "    #This function standardizes the column names across all the data frames (they were a *mess* in the raw data)\n",
    "\n",
    "    \n",
    "    global df19\n",
    "    df19 = pd.read_csv(instr(19))\n",
    "    global df20\n",
    "    df20 = pd.read_csv(instr(20))\n",
    "    global df21\n",
    "    df21 = pd.read_csv(instr(21))\n",
    "    global df22\n",
    "    df22 = pd.read_csv(instr(22))\n",
    "    global df23\n",
    "    df23 = pd.read_csv(instr(23))\n",
    "\n",
    "    global dfs\n",
    "    dfs = {\n",
    "        'df19': df19,\n",
    "        'df20': df20,\n",
    "        'df21': df21,\n",
    "        'df22': df22,\n",
    "        'df23': df23\n",
    "    }\n",
    "\n",
    "\n",
    "   \n",
    "\n",
    "    #Columns which were not available in every year. Remove, for consistency\n",
    "    cols_to_remove = [\n",
    "        \"Chronically Truant Students\",\n",
    "        \"Total Teacher Headcount\",\n",
    "        \"% Students with an IEP - Nat Haw/Other Pac Isndr\",\n",
    "        \"% Students with an IEP - Am Ind/Alaska Nat\",\n",
    "        \"% Students with an IEP - Two or More Races\",\"District Size\",\n",
    "        \"Avg Class Size - All Grades\"\n",
    "        ]\n",
    "\n",
    "    cols_to_fill_with_zero = [\n",
    "        \"% Student Enrollment - White\",\n",
    "        \"% Student Enrollment - Black or African American\",\n",
    "        \"% Student Enrollment - Hispanic or Latino\",\n",
    "        \"% Student Enrollment - Asian\",\n",
    "        \"% Student Enrollment - Native Hawaiian or Other Pacific Islander\",\n",
    "        \"% Student Enrollment - American Indian or Alaska Native\",\n",
    "        \"% Student Enrollment - Two or More Races\",\n",
    "        \"% Student Enrollment - Children with Disabilities\",\n",
    "        \"% Student Enrollment - EL\",\n",
    "        \"% Student Enrollment - IEP\",\n",
    "        \"% Student Enrollment - Low Income\",\n",
    "        \"% Student Enrollment - Homeless\",\n",
    "        \"% Students with an IEP - White\",\n",
    "        \"% Students with an IEP - Black or African American\",\n",
    "        \"% Students with an IEP - Hispanic or Latino\",\n",
    "        \"% Students with an IEP - Asian\"\n",
    "\n",
    "    ]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #Rename columns so they are consistent across years\n",
    "    for name, df in dfs.items():\n",
    "        for col in df.columns:\n",
    "            if \"Master\" in col:\n",
    "                df.rename(columns={col: \"Percent Teachers With Masters Degree\"}, inplace=True)\n",
    "            if \"Bachelor\" in col:\n",
    "                df.rename(columns={col: \"Percent Teachers With Bachelor Degree\"}, inplace=True)\n",
    "            if \"Attendace\" in col:\n",
    "                df.rename(columns={col: \"Teacher Attendance Rate\"}, inplace=True)\n",
    "            if \"SAT Math Average\" in col:\n",
    "                df.rename(columns={col: \"SAT Math Average\"}, inplace=True)\n",
    "            if \"SAT Reading Average\" in col:\n",
    "                df.rename(columns={col: \"SAT Reading Average\"}, inplace=True)\n",
    "            if \"Grades Served\" in col:\n",
    "                df.rename(columns= {col: \"Grades Served\"}, inplace=True)\n",
    "\n",
    "            #Remove columns we don't want that appear in some dfs\n",
    "            if col in cols_to_remove:\n",
    "                df.drop(columns=col, inplace=True)\n",
    "\n",
    "            #Some dfs leave 0s blank or filled with \"*\". Fill those with 0s.\n",
    "            df[cols_to_fill_with_zero] = df[cols_to_fill_with_zero].fillna(0)\n",
    "            df.replace('*', 0, inplace=True)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #Standardize punctuation\n",
    "    def clean_column_names(dfs, to_lower=False):\n",
    "        for name, df in dfs.items():\n",
    "            new_cols = []\n",
    "            for col in df.columns:\n",
    "                cleaned = col\n",
    "                cleaned = cleaned.replace(\"–\", \"-\").replace(\"—\", \"-\")  # Replace smart dashes with hyphen\n",
    "                cleaned = cleaned.replace(\"“\", '\"').replace(\"”\", '\"')  # Smart quotes to plain\n",
    "                cleaned = cleaned.replace(\"‘\", \"'\").replace(\"’\", \"'\")  # Smart apostrophes\n",
    "                cleaned = re.sub(r\"\\s+\", \" \", cleaned)                # Collapse multiple spaces\n",
    "                cleaned = cleaned.strip()                             # Remove leading/trailing spaces\n",
    "                if to_lower:\n",
    "                    cleaned = cleaned.lower()\n",
    "                new_cols.append(cleaned)\n",
    "            df.columns = new_cols\n",
    "            print(f\"Cleaned column names for {name}\")\n",
    "\n",
    "    clean_column_names(dfs, to_lower=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "96924488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Still using the same dictionary of dataframes\n",
    "\n",
    "def check():\n",
    "    #Module to check which column names don't appear in every data frame year\n",
    "\n",
    "    from collections import Counter, defaultdict\n",
    "\n",
    "    # Step 1: Count all column names\n",
    "    all_columns = [col for df in dfs.values() for col in df.columns]\n",
    "    column_counts = Counter(all_columns)\n",
    "\n",
    "    # Step 2: For each non-universal column, list which dataframes include it\n",
    "    columns_with_sources = defaultdict(list)\n",
    "\n",
    "    for col in column_counts:\n",
    "        if column_counts[col] < 5:\n",
    "            for name, df in dfs.items():\n",
    "                if col in df.columns:\n",
    "                    columns_with_sources[col].append(name)\n",
    "\n",
    "    # Step 3: Print the results\n",
    "    print(\"Columns that do NOT appear in all 5 dataframes:\\n\")\n",
    "    for col, present_in in columns_with_sources.items():\n",
    "        print(f\"'{col}' appears in: {', '.join(present_in)}\")\n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f68f50a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned column names for df19\n",
      "Cleaned column names for df20\n",
      "Cleaned column names for df21\n",
      "Cleaned column names for df22\n",
      "Cleaned column names for df23\n",
      "Columns that do NOT appear in all 5 dataframes:\n",
      "\n",
      "(713, 51)\n",
      "(691, 51)\n",
      "(701, 51)\n",
      "(700, 51)\n",
      "(692, 52)\n",
      "Filled 51 missing dropout rates in df22.\n"
     ]
    }
   ],
   "source": [
    "#Whip that data into shape!\n",
    "merge()\n",
    "cleaner()\n",
    "check()\n",
    "\n",
    "#Drop all rows without SAT data\n",
    "for key in dfs:\n",
    "    df = dfs[key]\n",
    "\n",
    "    # Coerce non-numeric values to NaN\n",
    "    df[\"SAT Math Average\"] = pd.to_numeric(df[\"SAT Math Average\"], errors='coerce')\n",
    "\n",
    "    # Drop rows where the value is NaN or 0\n",
    "    df = df.dropna(subset=[\"SAT Math Average\"])\n",
    "    df = df[df[\"SAT Math Average\"] != 0]\n",
    "\n",
    "    print(df.shape)\n",
    "    # Reset index and store back in dict\n",
    "    dfs[key] = df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "# First, ensure all three DataFrames have the right column as numeric\n",
    "for df in [df21, df22, df23]:\n",
    "    df[\"High School Dropout Rate - Total\"] = pd.to_numeric(\n",
    "        df[\"High School Dropout Rate - Total\"], errors='coerce'\n",
    "    )\n",
    "\n",
    "# Create a mapping from RCDTS to dropout rate for df21 and df23\n",
    "dropout_21 = df21.set_index(\"RCDTS\")[\"High School Dropout Rate - Total\"]\n",
    "dropout_23 = df23.set_index(\"RCDTS\")[\"High School Dropout Rate - Total\"]\n",
    "\n",
    "# Function to get average from df21 and df23 if both exist\n",
    "def average_if_available(rcdts):\n",
    "    val_21 = dropout_21.get(rcdts, np.nan)\n",
    "    val_23 = dropout_23.get(rcdts, np.nan)\n",
    "    if pd.notna(val_21) and pd.notna(val_23):\n",
    "        return (val_21 + val_23) / 2\n",
    "    else:\n",
    "        return np.nan  # don't fill if we can't get both\n",
    "\n",
    "# Apply this to missing rows in df22\n",
    "mask_missing = df22[\"High School Dropout Rate - Total\"].isna()\n",
    "df22.loc[mask_missing, \"High School Dropout Rate - Total\"] = df22.loc[mask_missing, \"RCDTS\"].apply(average_if_available)\n",
    "\n",
    "# Print how many we successfully filled\n",
    "filled_count = mask_missing.sum() - df22[\"High School Dropout Rate - Total\"].isna().sum()\n",
    "print(f\"Filled {filled_count} missing dropout rates in df22.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4027271b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export nice data frames\n",
    "df19 = dfs['df19']\n",
    "df20 = dfs['df20']\n",
    "df21 = dfs['df21']\n",
    "df22 = dfs['df22']\n",
    "df23 = dfs['df23']\n",
    "\n",
    "df19.to_csv(instr(19),index=False)\n",
    "df20.to_csv(instr(20),index=False)\n",
    "df21.to_csv(instr(21),index=False)\n",
    "df22.to_csv(instr(22),index=False)\n",
    "df23.to_csv(instr(23),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8887c29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
