{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "import googlemaps\n",
    "import concurrent.futures\n",
    "import io\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This whole cell just sets up our functions to handle various api calls\n",
    "\n",
    "# Set up Google Maps API client\n",
    "def load_api_key(filepath):\n",
    "    \"\"\"Reads API key from a text file.\"\"\"\n",
    "    with open(filepath, \"r\") as file:\n",
    "        return file.read().strip()\n",
    "\n",
    "API_KEY = load_api_key(\"../../Google_API_Key.txt\")  #Replace with your API key (not provided in git repo)\n",
    "gmaps = googlemaps.Client(key=API_KEY)\n",
    "\n",
    "def get_location_details_google(row):\n",
    "    \"\"\"Fetch latitude, longitude, full street address, ZIP code, and county from Google Maps API.\"\"\"\n",
    "    \n",
    "    if \"District Name\" in row:\n",
    "        query = f\"{row['School Name']}, {row['District Name']}, {state}, High School\"\n",
    "    else:\n",
    "        query = f\"{row['School Name']}, {state}, High School\"\n",
    "\n",
    "    \n",
    "    try:\n",
    "        geocode_result = gmaps.geocode(query)\n",
    "        if geocode_result:\n",
    "            location = geocode_result[0][\"geometry\"][\"location\"]\n",
    "            lat, lon = location[\"lat\"], location[\"lng\"]\n",
    "            \n",
    "            \n",
    "            # Extract address components\n",
    "            address_components = geocode_result[0].get(\"address_components\", [])\n",
    "            street_number, street_name, zip_code, county, city = \"\", \"\", \"N/A\", \"N/A\", \"N/A\"\n",
    "            \n",
    "            for component in address_components:\n",
    "                types = component[\"types\"]\n",
    "                if \"street_number\" in types:\n",
    "                    street_number = component[\"long_name\"]\n",
    "                if \"route\" in types:\n",
    "                    street_name = component[\"long_name\"]\n",
    "                if \"postal_code\" in types:\n",
    "                    zip_code = component[\"long_name\"]\n",
    "                if \"administrative_area_level_2\" in types:\n",
    "                    county = component[\"long_name\"]\n",
    "                if \"locality\" in types:  # This is for city\n",
    "                    city = component[\"long_name\"]\n",
    "            \n",
    "                    \n",
    "            full_street_address = f\"{street_number} {street_name}\".strip()\n",
    "            return pd.Series([lat, lon, full_street_address,  zip_code, county, city])\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching details for {query}: {e}\")\n",
    "    \n",
    "    return pd.Series([\"N/A\", \"N/A\", \"N/A\", \"N/A\", \"N/A\"])\n",
    "\n",
    "\n",
    "def fetch_missing_county_names(df, gmaps, state):\n",
    "    \"\"\"Fill in missing or 'N/A' county names using Google Maps API.\"\"\"\n",
    "\n",
    "    def get_county_only(row):\n",
    "        if pd.notna(row['county_name']) and row['county_name'].strip().upper() != \"N/A\":\n",
    "            return row['county_name'].strip()  # Already exists and is valid\n",
    "\n",
    "        if pd.isna(row[\"latitude\"]) or pd.isna(row[\"longitude\"]):\n",
    "            return None\n",
    "\n",
    "        try:\n",
    "            result = gmaps.reverse_geocode((row[\"latitude\"], row[\"longitude\"]))\n",
    "            for component in result[0].get(\"address_components\", []):\n",
    "                if \"administrative_area_level_2\" in component[\"types\"]:\n",
    "                    return component[\"long_name\"].strip()\n",
    "        except Exception as e:\n",
    "            print(f\"Error for index {row.name}: {e}\")\n",
    "            return None\n",
    "\n",
    "    df[\"county_name\"] = df.apply(get_county_only, axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "    df[\"county_name\"] = df.apply(get_county_only, axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_census_tract(lat, lon):\n",
    "    \"\"\"Fetch the census tract for given latitude and longitude using the Census Geocoder API.\"\"\"\n",
    "    # url = f\"https://geocoding.geo.census.gov/geocoder/geographies/coordinates?x={lon}&y={lat}&benchmark=Public_AR_2020&vintage=Census2020_Census2020&layers=10&format=json\"\n",
    "    url = f\"https://geocoding.geo.census.gov/geocoder/geographies/coordinates?x={lon}&y={lat}&benchmark=Public_AR_Current&vintage=Current_Current&layers=10&format=json\"\n",
    "\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url, timeout=5)  # Set timeout to avoid hanging requests\n",
    "        response.raise_for_status()  # Raise an error for HTTP issues\n",
    "        data = response.json()\n",
    "        \n",
    "        geographies = data.get('result', {}).get('geographies', {})\n",
    "        if 'Census Block Groups' in geographies:\n",
    "            tract_id = str(geographies['Census Block Groups'][0].get('TRACT', 'Not found'))\n",
    "            return tract_id.zfill(6)  # Ensure 6-digit format\n",
    "        return 'No data'\n",
    "    \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return f\"Error: {e}\"\n",
    "\n",
    "\n",
    "\n",
    "def add_missing_census_tracts(df, max_workers=5):\n",
    "    \"\"\"Only fetch census tracts for rows where Tract == '000000'.\"\"\"\n",
    "    \n",
    "    # Filter rows with bad tract data\n",
    "    mask = df['Tract'] == \"000000\"\n",
    "    df_missing = df[mask].copy()\n",
    "\n",
    "    if df_missing.empty:\n",
    "        print(\"No missing tracts to update.\")\n",
    "        return df\n",
    "    \n",
    "    print(f\"Updating {len(df_missing)} missing tracts...\")\n",
    "\n",
    "    # Fetch the good tracts\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        new_tracts = list(executor.map(get_census_tract, df_missing['latitude'], df_missing['longitude']))\n",
    "\n",
    "    # Update only those rows in the original dataframe\n",
    "    df.loc[mask, 'Tract'] = new_tracts\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def batch_census_tract(indf):\n",
    "\n",
    "    #Takes in data frame, indf which has column heads, among others, \"Address\", \"City\", \"State\", and \"Zip\" and batch looks up census tract info.\n",
    "\n",
    "    indf[\"Unique ID\"] = indf.index\n",
    "\n",
    "    df2=indf[[\"address\",\"city_name\",\"state_name\",\"zip_code\",\"Unique ID\"]] #grab just relevant columns\n",
    "\n",
    "    # Remove rows where 'Address' is NaN or an empty string\n",
    "    df2 = df2[df2['address'].notna() & (df2['address'] != '')]\n",
    "    df2 =  df2[df2['city_name'].notna() & (df2['city_name'] != '')]\n",
    "    df2.columns = [\"Street Address\",\"City\",\"State\",\"Zip\",\"Unique ID\"]\n",
    "    df2 = df2[[\"Unique ID\"] + [col for col in df2.columns if col != \"unique ID\"]] #Unique ID needs to be first column\n",
    "\n",
    "    csv_buffer = io.StringIO()\n",
    "    df2.to_csv(csv_buffer, index=False, header=False, quoting=1)  # quoting=1 forces proper quoting\n",
    "    csv_buffer.seek(0)  # Move to the start of the buffer\n",
    "\n",
    "    # API Endpoint\n",
    "    url = \"https://geocoding.geo.census.gov/geocoder/geographies/addressbatch\"\n",
    "    # url = \"https://geocoding.geo.census.gov/geocoder/geographies/addressbatch?benchmark=Public_AR_2020&vintage=Census2020_Census2020\"\n",
    "\n",
    "    # API Request with in-memory file\n",
    "    files = {\"addressFile\": (\"addresses.csv\", csv_buffer.getvalue())}\n",
    "    data = {\"benchmark\": \"4\", \"vintage\": \"4\"}\n",
    "\n",
    "    response = requests.post(url, files=files, data=data)\n",
    "\n",
    "    # Read response into a new DataFrame (FIXED!)\n",
    "    result_buffer = io.StringIO(response.text)\n",
    "\n",
    "    result_df = pd.read_csv(\n",
    "    result_buffer,\n",
    "    header=None,\n",
    "    quotechar='\"',  # This ensures that quoted fields (like addresses and lat/lon) stay intact\n",
    "    names=[\n",
    "        \"Unique ID\", \"Street Address\", \"Match Status\", \"Match Type\", \n",
    "        \"Standardized Address\", \"Coordinates\", \"TigerLine ID\", \"Side\", \n",
    "        \"State FIPS\", \"County FIPS\", \"Tract\", \"Block\"\n",
    "    ]\n",
    "    )\n",
    "\n",
    "    # Split Latitude and Longitude.\n",
    "    result_df[['Longitude', 'Latitude']] = result_df['Coordinates'].str.split(',', expand=True)\n",
    "    result_df.drop(columns=['Coordinates'], inplace=True)  # Drop combined colum\n",
    "\n",
    "    result_df[\"Tract\"] = result_df[\"Tract\"].fillna(0).astype(int)  # Fill NaNs with 0 and then convert\n",
    "    result_df.loc[result_df[\"Tract\"]==0, \"Tract\"] = \"\" \n",
    "\n",
    "    #Fill in updated county code when possible\n",
    "    result_df = result_df.set_index(\"Unique ID\")\n",
    "    indf[\"county_code\"] = indf[\"county_code\"].fillna(result_df[\"County FIPS\"])\n",
    "    result_df = result_df.reset_index()\n",
    "\n",
    "    #Drop Unnec. Columns\n",
    "    result_df = result_df.drop(columns = [\"Match Status\", \"Match Type\", \"Standardized Address\", \"Side\",\"State FIPS\",\"TigerLine ID\",\"Block\",\"County FIPS\",\"Latitude\",\"Longitude\"])\n",
    "\n",
    "    #Merge Results\n",
    "    indf = indf.merge(result_df,on=\"Unique ID\", how = \"left\")\n",
    "    indf = indf.drop(columns = [\"Unique ID\"])\n",
    "    indf[\"Tract\"] = indf[\"Tract\"].fillna(\"\")\n",
    "\n",
    "    #Pad Tract ID to 6 digit format\n",
    "    indf[\"Tract\"] = indf[\"Tract\"].astype(str).str.zfill(6)\n",
    "\n",
    "    #return modified input df\n",
    "    return indf\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_724776/2417638269.py:173: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  result_df.loc[result_df[\"Tract\"]==0, \"Tract\"] = \"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating 129 missing tracts...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>School Name</th>\n",
       "      <th>Tests Taken</th>\n",
       "      <th>Reading / Writing</th>\n",
       "      <th>Writing</th>\n",
       "      <th>Math</th>\n",
       "      <th>state_name_x</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>address</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>...</th>\n",
       "      <th>American Indian and Alaska Native alone (estimate)</th>\n",
       "      <th>American Indian and Alaska Native alone (percentage)</th>\n",
       "      <th>Asian alone (estimate)</th>\n",
       "      <th>Asian alone (percentage)</th>\n",
       "      <th>Native Hawaiian and Other Pacific Islander alone (estimate)</th>\n",
       "      <th>Native Hawaiian and Other Pacific Islander alone (percentage)</th>\n",
       "      <th>Some other race alone (estimate)</th>\n",
       "      <th>Some other race alone (percentage)</th>\n",
       "      <th>Two or more races alone (estimate)</th>\n",
       "      <th>Two or more races alone (percentage)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abby Kelley Foster Charter Public (District) -...</td>\n",
       "      <td>106</td>\n",
       "      <td>536.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>524.0</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>42.306192</td>\n",
       "      <td>-71.802933</td>\n",
       "      <td>10 New Bond Street</td>\n",
       "      <td>01606</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>654.0</td>\n",
       "      <td>10.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abington - Abington High</td>\n",
       "      <td>148</td>\n",
       "      <td>528.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>525.0</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>42.119016</td>\n",
       "      <td>-70.953162</td>\n",
       "      <td>201 Gliniewicz Way</td>\n",
       "      <td>02351</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>423.0</td>\n",
       "      <td>7.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Academy Of the Pacific Rim Charter Public (Dis...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>42.244480</td>\n",
       "      <td>-71.131898</td>\n",
       "      <td>1 Westinghouse Plaza</td>\n",
       "      <td>02136</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Acton-Boxborough - Acton-Boxborough Regional High</td>\n",
       "      <td>343</td>\n",
       "      <td>648.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>677.0</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>42.479696</td>\n",
       "      <td>-71.458081</td>\n",
       "      <td>36 Charter Road</td>\n",
       "      <td>01720</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1004.0</td>\n",
       "      <td>26.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>243.0</td>\n",
       "      <td>6.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adams-Cheshire - Hoosac Valley High School</td>\n",
       "      <td>73</td>\n",
       "      <td>524.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>516.0</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>42.594559</td>\n",
       "      <td>-73.115036</td>\n",
       "      <td>125 Savoy Road</td>\n",
       "      <td>01225</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         School Name  Tests Taken  \\\n",
       "0  Abby Kelley Foster Charter Public (District) -...          106   \n",
       "1                           Abington - Abington High          148   \n",
       "2  Academy Of the Pacific Rim Charter Public (Dis...            1   \n",
       "3  Acton-Boxborough - Acton-Boxborough Regional High          343   \n",
       "4         Adams-Cheshire - Hoosac Valley High School           73   \n",
       "\n",
       "   Reading / Writing  Writing   Math   state_name_x   latitude  longitude  \\\n",
       "0              536.0      NaN  524.0  Massachusetts  42.306192 -71.802933   \n",
       "1              528.0      NaN  525.0  Massachusetts  42.119016 -70.953162   \n",
       "2                NaN      NaN    NaN  Massachusetts  42.244480 -71.131898   \n",
       "3              648.0      NaN  677.0  Massachusetts  42.479696 -71.458081   \n",
       "4              524.0      NaN  516.0  Massachusetts  42.594559 -73.115036   \n",
       "\n",
       "                address zip_code  ...  \\\n",
       "0    10 New Bond Street    01606  ...   \n",
       "1    201 Gliniewicz Way    02351  ...   \n",
       "2  1 Westinghouse Plaza    02136  ...   \n",
       "3       36 Charter Road    01720  ...   \n",
       "4        125 Savoy Road    01225  ...   \n",
       "\n",
       "  American Indian and Alaska Native alone (estimate)  \\\n",
       "0                                                0.0   \n",
       "1                                                0.0   \n",
       "2                                                0.0   \n",
       "3                                                0.0   \n",
       "4                                                7.0   \n",
       "\n",
       "  American Indian and Alaska Native alone (percentage) Asian alone (estimate)  \\\n",
       "0                                                0.0                    654.0   \n",
       "1                                                0.0                    219.0   \n",
       "2                                                0.0                    220.0   \n",
       "3                                                0.0                   1004.0   \n",
       "4                                                0.2                      0.0   \n",
       "\n",
       "  Asian alone (percentage)  \\\n",
       "0                     10.3   \n",
       "1                      3.7   \n",
       "2                      3.8   \n",
       "3                     26.4   \n",
       "4                      0.0   \n",
       "\n",
       "  Native Hawaiian and Other Pacific Islander alone (estimate)  \\\n",
       "0                                                0.0            \n",
       "1                                                0.0            \n",
       "2                                                0.0            \n",
       "3                                                0.0            \n",
       "4                                                0.0            \n",
       "\n",
       "  Native Hawaiian and Other Pacific Islander alone (percentage)  \\\n",
       "0                                                0.0              \n",
       "1                                                0.0              \n",
       "2                                                0.0              \n",
       "3                                                0.0              \n",
       "4                                                0.0              \n",
       "\n",
       "   Some other race alone (estimate)  Some other race alone (percentage)  \\\n",
       "0                              47.0                                 0.7   \n",
       "1                               0.0                                 0.0   \n",
       "2                               0.0                                 0.0   \n",
       "3                               0.0                                 0.0   \n",
       "4                               0.0                                 0.0   \n",
       "\n",
       "  Two or more races alone (estimate) Two or more races alone (percentage)  \n",
       "0                              162.0                                  2.5  \n",
       "1                              423.0                                  7.1  \n",
       "2                              109.0                                  1.9  \n",
       "3                              243.0                                  6.4  \n",
       "4                               96.0                                  3.1  \n",
       "\n",
       "[5 rows x 66 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = \"Massachusetts\"  # State\n",
    "input_ed_csv = \"/home/mark/Documents/Erdos/Proj/math_ed_project/data/MA19/MA19_ed_data.csv\" # Input education data file\n",
    "input_census_csv = \"/home/mark/Documents/Erdos/Proj/math_ed_project/data/census_data/MA/20/MA20_census_data.csv\" #Input census data file\n",
    "input_county_csv = \"~/Documents/Erdos/Proj/math_ed_project/data/county_codes.csv\" #Path to County Codes\n",
    "output_csv = \"/home/mark/Documents/Erdos/Proj/math_ed_project/data/MA19/MA19_Combined_Census_Education.csv\"  # Output file\n",
    "\n",
    "\n",
    "def build_csv(input_ed_csv,input_census_csv,input_county_csv,state,output_csv):\n",
    "    #Takes input_ed_csv, input_census_csv, and input_county_csv, and combines into single csv.\n",
    "    # *_csv arguments are all filepaths to csv file.\n",
    "    # state is a string specifying which state this applies to.\n",
    "   \n",
    "\n",
    "    #Import and format county code data\n",
    "    countydf=pd.read_csv(input_county_csv)\n",
    "    countydf[\"state_name\"] = countydf[\"state_name\"].str.strip()\n",
    "    countydf[\"county_name\"] = countydf[\"county_name\"].str.strip()\n",
    "    countydf[\"county_code\"] = countydf[\"county_code\"].astype(str)\n",
    "\n",
    "    # Read ed_CSV into Pandas DataFrame\n",
    "    ext = input_ed_csv.split('.')[-1] #Get the file type, since they're not all csv files.\n",
    "    if ext == \"csv\":\n",
    "        df = pd.read_csv(input_ed_csv)\n",
    "    else:\n",
    "        df = df = pd.read_excel(input_ed_csv)\n",
    "\n",
    "    #Can't work with entries with no school name\n",
    "    df = df.dropna(subset=[\"School Name\"])\n",
    "\n",
    "\n",
    "    #Read census_CSV into data frame. Make unique ID a string, which ends up being convenient.\n",
    "    dfcensus = pd.read_csv(input_census_csv)\n",
    "    dfcensus[\"unique_id\"]=dfcensus[\"unique_id\"].astype(str)\n",
    "\n",
    "    #Fetch Geo data using google maps API\n",
    "  # Apply the function to get location details and add the resulting columns to the DataFrame\n",
    "    df[\"state_name\"] = state\n",
    "    df[[\"latitude\", \"longitude\", \"address\", \"zip_code\", \"county_name\", \"city_name\"]] = df.apply(get_location_details_google, axis=1)\n",
    "\n",
    "    #For whatever reason google doesn't succeed at grabbing all the county names at first pass.\n",
    "    fetch_missing_county_names(df,gmaps,state)\n",
    "    \n",
    "    #Load County ID data into df\n",
    "    df = df.merge(countydf, on=[\"state_name\", \"county_name\"], how=\"left\")\n",
    "\n",
    "\n",
    "    #First do batch census geoprocessing wherever possible\n",
    "    df = batch_census_tract(df)\n",
    "\n",
    "\n",
    "    #only then do individual census geoprocessing, on the stragglers\n",
    "    df = add_missing_census_tracts(df)\n",
    "\n",
    "      \n",
    "    df[\"unique_id\"] = df[\"county_code\"].astype(str) + df[\"Tract\"].astype(str)\n",
    "\n",
    "\n",
    "    df = df.merge(dfcensus, on=\"unique_id\", how=\"left\")\n",
    "\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "df = build_csv(input_ed_csv,input_census_csv,input_county_csv,state,output_csv)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finally, check that there weren't too many errors in the merging. If not, write out to csv.\n",
    "if (df[df[\"American Indian and Alaska Native alone (estimate)\"].isna()].shape)[0] <10:\n",
    "    df = df.dropna(subset = [\"American Indian and Alaska Native alone (estimate)\"])\n",
    "    df.to_csv(output_csv, index=False)\n",
    "else:\n",
    "    print(\"false\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
