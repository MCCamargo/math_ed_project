{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "import googlemaps\n",
    "import concurrent.futures\n",
    "import io\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This whole cell just sets up our functions to handle various api calls\n",
    "\n",
    "# Set up Google Maps API client\n",
    "def load_api_key(filepath):\n",
    "    \"\"\"Reads API key from a text file.\"\"\"\n",
    "    with open(filepath, \"r\") as file:\n",
    "        return file.read().strip()\n",
    "\n",
    "API_KEY = load_api_key(\"../../Google_API_Key.txt\")  #Replace with your API key (not provided in git repo)\n",
    "gmaps = googlemaps.Client(key=API_KEY)\n",
    "\n",
    "def get_location_details_google(row):\n",
    "    \"\"\"Fetch latitude, longitude, full street address, ZIP code, and county from Google Maps API.\"\"\"\n",
    "    \n",
    "    if \"District Name\" in row:\n",
    "        query = f\"{row['School Name']}, {row['District Name']}, {state}, High School\"\n",
    "    else:\n",
    "        query = f\"{row['School Name']}, {state}, High School\"\n",
    "\n",
    "    \n",
    "    try:\n",
    "        geocode_result = gmaps.geocode(query)\n",
    "        if geocode_result:\n",
    "            location = geocode_result[0][\"geometry\"][\"location\"]\n",
    "            lat, lon = location[\"lat\"], location[\"lng\"]\n",
    "            \n",
    "            \n",
    "            # Extract address components\n",
    "            address_components = geocode_result[0].get(\"address_components\", [])\n",
    "            street_number, street_name, zip_code, county, city = \"\", \"\", \"N/A\", \"N/A\", \"N/A\"\n",
    "            \n",
    "            for component in address_components:\n",
    "                types = component[\"types\"]\n",
    "                if \"street_number\" in types:\n",
    "                    street_number = component[\"long_name\"]\n",
    "                if \"route\" in types:\n",
    "                    street_name = component[\"long_name\"]\n",
    "                if \"postal_code\" in types:\n",
    "                    zip_code = component[\"long_name\"]\n",
    "                if \"administrative_area_level_2\" in types:\n",
    "                    county = component[\"long_name\"]\n",
    "                if \"locality\" in types:  # This is for city\n",
    "                    city = component[\"long_name\"]\n",
    "            \n",
    "                    \n",
    "            full_street_address = f\"{street_number} {street_name}\".strip()\n",
    "            return pd.Series([lat, lon, full_street_address,  zip_code, county, city])\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching details for {query}: {e}\")\n",
    "    \n",
    "    return pd.Series([\"N/A\", \"N/A\", \"N/A\", \"N/A\", \"N/A\"])\n",
    "\n",
    "\n",
    "def fetch_missing_county_names(df, gmaps, state):\n",
    "    \"\"\"Fill in missing or 'N/A' county names using Google Maps API.\"\"\"\n",
    "\n",
    "    def get_county_only(row):\n",
    "        if pd.notna(row['county_name']) and row['county_name'].strip().upper() != \"N/A\":\n",
    "            return row['county_name'].strip()  # Already exists and is valid\n",
    "\n",
    "        if pd.isna(row[\"latitude\"]) or pd.isna(row[\"longitude\"]):\n",
    "            return None\n",
    "\n",
    "        try:\n",
    "            result = gmaps.reverse_geocode((row[\"latitude\"], row[\"longitude\"]))\n",
    "            for component in result[0].get(\"address_components\", []):\n",
    "                if \"administrative_area_level_2\" in component[\"types\"]:\n",
    "                    return component[\"long_name\"].strip()\n",
    "        except Exception as e:\n",
    "            print(f\"Error for index {row.name}: {e}\")\n",
    "            return None\n",
    "\n",
    "    df[\"county_name\"] = df.apply(get_county_only, axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "    df[\"county_name\"] = df.apply(get_county_only, axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_census_tract(lat, lon):\n",
    "    \"\"\"Fetch the census tract for given latitude and longitude using the Census Geocoder API.\"\"\"\n",
    "    # url = f\"https://geocoding.geo.census.gov/geocoder/geographies/coordinates?x={lon}&y={lat}&benchmark=Public_AR_2020&vintage=Census2020_Census2020&layers=10&format=json\"\n",
    "    url = f\"https://geocoding.geo.census.gov/geocoder/geographies/coordinates?x={lon}&y={lat}&benchmark=Public_AR_Current&vintage=Current_Current&layers=10&format=json\"\n",
    "\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url, timeout=5)  # Set timeout to avoid hanging requests\n",
    "        response.raise_for_status()  # Raise an error for HTTP issues\n",
    "        data = response.json()\n",
    "        \n",
    "        geographies = data.get('result', {}).get('geographies', {})\n",
    "        if 'Census Block Groups' in geographies:\n",
    "            tract_id = str(geographies['Census Block Groups'][0].get('TRACT', 'Not found'))\n",
    "            return tract_id.zfill(6)  # Ensure 6-digit format\n",
    "        return 'No data'\n",
    "    \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return f\"Error: {e}\"\n",
    "\n",
    "\n",
    "\n",
    "def add_missing_census_tracts(df, max_workers=5):\n",
    "    \"\"\"Only fetch census tracts for rows where Tract == '000000'.\"\"\"\n",
    "    \n",
    "    # Filter rows with bad tract data\n",
    "    mask = df['Tract'] == \"000000\"\n",
    "    df_missing = df[mask].copy()\n",
    "\n",
    "    if df_missing.empty:\n",
    "        print(\"No missing tracts to update.\")\n",
    "        return df\n",
    "    \n",
    "    print(f\"Updating {len(df_missing)} missing tracts...\")\n",
    "\n",
    "    # Fetch the good tracts\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        new_tracts = list(executor.map(get_census_tract, df_missing['latitude'], df_missing['longitude']))\n",
    "\n",
    "    # Update only those rows in the original dataframe\n",
    "    df.loc[mask, 'Tract'] = new_tracts\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def batch_census_tract(indf):\n",
    "\n",
    "    #Takes in data frame, indf which has column heads, among others, \"Address\", \"City\", \"State\", and \"Zip\" and batch looks up census tract info.\n",
    "\n",
    "    indf[\"Unique ID\"] = indf.index\n",
    "\n",
    "    df2=indf[[\"address\",\"city_name\",\"state_name\",\"zip_code\",\"Unique ID\"]] #grab just relevant columns\n",
    "\n",
    "    # Remove rows where 'Address' is NaN or an empty string\n",
    "    df2 = df2[df2['address'].notna() & (df2['address'] != '')]\n",
    "    df2 =  df2[df2['city_name'].notna() & (df2['city_name'] != '')]\n",
    "    df2.columns = [\"Street Address\",\"City\",\"State\",\"Zip\",\"Unique ID\"]\n",
    "    df2 = df2[[\"Unique ID\"] + [col for col in df2.columns if col != \"unique ID\"]] #Unique ID needs to be first column\n",
    "\n",
    "    csv_buffer = io.StringIO()\n",
    "    df2.to_csv(csv_buffer, index=False, header=False, quoting=1)  # quoting=1 forces proper quoting\n",
    "    csv_buffer.seek(0)  # Move to the start of the buffer\n",
    "\n",
    "    # API Endpoint\n",
    "    url = \"https://geocoding.geo.census.gov/geocoder/geographies/addressbatch\"\n",
    "    # url = \"https://geocoding.geo.census.gov/geocoder/geographies/addressbatch?benchmark=Public_AR_2020&vintage=Census2020_Census2020\"\n",
    "\n",
    "    # API Request with in-memory file\n",
    "    files = {\"addressFile\": (\"addresses.csv\", csv_buffer.getvalue())}\n",
    "    data = {\"benchmark\": \"4\", \"vintage\": \"4\"}\n",
    "\n",
    "    response = requests.post(url, files=files, data=data)\n",
    "\n",
    "    # Read response into a new DataFrame (FIXED!)\n",
    "    result_buffer = io.StringIO(response.text)\n",
    "\n",
    "    result_df = pd.read_csv(\n",
    "    result_buffer,\n",
    "    header=None,\n",
    "    quotechar='\"',  # This ensures that quoted fields (like addresses and lat/lon) stay intact\n",
    "    names=[\n",
    "        \"Unique ID\", \"Street Address\", \"Match Status\", \"Match Type\", \n",
    "        \"Standardized Address\", \"Coordinates\", \"TigerLine ID\", \"Side\", \n",
    "        \"State FIPS\", \"County FIPS\", \"Tract\", \"Block\"\n",
    "    ]\n",
    "    )\n",
    "\n",
    "    # Split Latitude and Longitude.\n",
    "    result_df[['Longitude', 'Latitude']] = result_df['Coordinates'].str.split(',', expand=True)\n",
    "    result_df.drop(columns=['Coordinates'], inplace=True)  # Drop combined colum\n",
    "\n",
    "    result_df[\"Tract\"] = result_df[\"Tract\"].fillna(0).astype(int)  # Fill NaNs with 0 and then convert\n",
    "    result_df.loc[result_df[\"Tract\"]==0, \"Tract\"] = \"\" \n",
    "\n",
    "    #Fill in updated county code when possible\n",
    "    result_df = result_df.set_index(\"Unique ID\")\n",
    "    indf[\"county_code\"] = indf[\"county_code\"].fillna(result_df[\"County FIPS\"])\n",
    "    result_df = result_df.reset_index()\n",
    "\n",
    "    #Drop Unnec. Columns\n",
    "    result_df = result_df.drop(columns = [\"Match Status\", \"Match Type\", \"Standardized Address\", \"Side\",\"State FIPS\",\"TigerLine ID\",\"Block\",\"County FIPS\",\"Latitude\",\"Longitude\"])\n",
    "\n",
    "    #Merge Results\n",
    "    indf = indf.merge(result_df,on=\"Unique ID\", how = \"left\")\n",
    "    indf = indf.drop(columns = [\"Unique ID\"])\n",
    "    indf[\"Tract\"] = indf[\"Tract\"].fillna(\"\")\n",
    "\n",
    "    #Pad Tract ID to 6 digit format\n",
    "    indf[\"Tract\"] = indf[\"Tract\"].astype(str).str.zfill(6)\n",
    "\n",
    "    #return modified input df\n",
    "    return indf\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for index 209: could not convert string to float: 'N/A'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_193735/484987159.py:175: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  result_df.loc[result_df[\"Tract\"]==0, \"Tract\"] = \"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating 202 missing tracts...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>RCDTS</th>\n",
       "      <th>Type</th>\n",
       "      <th>School Name</th>\n",
       "      <th>District</th>\n",
       "      <th>City</th>\n",
       "      <th>County</th>\n",
       "      <th>District Type</th>\n",
       "      <th>District Size</th>\n",
       "      <th>School Type</th>\n",
       "      <th>...</th>\n",
       "      <th>American Indian and Alaska Native alone (estimate)</th>\n",
       "      <th>American Indian and Alaska Native alone (percentage)</th>\n",
       "      <th>Asian alone (estimate)</th>\n",
       "      <th>Asian alone (percentage)</th>\n",
       "      <th>Native Hawaiian and Other Pacific Islander alone (estimate)</th>\n",
       "      <th>Native Hawaiian and Other Pacific Islander alone (percentage)</th>\n",
       "      <th>Some other race alone (estimate)</th>\n",
       "      <th>Some other race alone (percentage)</th>\n",
       "      <th>Two or more races alone (estimate)</th>\n",
       "      <th>Two or more races alone (percentage)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>010010010260001</td>\n",
       "      <td>School</td>\n",
       "      <td>Seymour High School</td>\n",
       "      <td>Payson CUSD 1</td>\n",
       "      <td>Payson</td>\n",
       "      <td>Adams</td>\n",
       "      <td>UNIT</td>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>HIGH SCHOOL</td>\n",
       "      <td>...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>010010020260001</td>\n",
       "      <td>School</td>\n",
       "      <td>Liberty High School</td>\n",
       "      <td>Liberty CUSD 2</td>\n",
       "      <td>Liberty</td>\n",
       "      <td>Adams</td>\n",
       "      <td>UNIT</td>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>HIGH SCHOOL</td>\n",
       "      <td>...</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>010010030260001</td>\n",
       "      <td>School</td>\n",
       "      <td>Central High School</td>\n",
       "      <td>Central CUSD 3</td>\n",
       "      <td>Camp Point</td>\n",
       "      <td>Adams</td>\n",
       "      <td>UNIT</td>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>HIGH SCHOOL</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>010010040260001</td>\n",
       "      <td>School</td>\n",
       "      <td>Unity High School</td>\n",
       "      <td>CUSD 4</td>\n",
       "      <td>Mendon</td>\n",
       "      <td>Adams</td>\n",
       "      <td>UNIT</td>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>HIGH SCHOOL</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>152.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>010011720220003</td>\n",
       "      <td>School</td>\n",
       "      <td>Quincy Sr High School</td>\n",
       "      <td>Quincy SD 172</td>\n",
       "      <td>Quincy</td>\n",
       "      <td>Adams</td>\n",
       "      <td>UNIT</td>\n",
       "      <td>LARGE</td>\n",
       "      <td>HIGH SCHOOL</td>\n",
       "      <td>...</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>101.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0            RCDTS    Type            School Name        District  \\\n",
       "0           1  010010010260001  School    Seymour High School   Payson CUSD 1   \n",
       "1           4  010010020260001  School    Liberty High School  Liberty CUSD 2   \n",
       "2           7  010010030260001  School    Central High School  Central CUSD 3   \n",
       "3          12  010010040260001  School      Unity High School          CUSD 4   \n",
       "4          16  010011720220003  School  Quincy Sr High School   Quincy SD 172   \n",
       "\n",
       "         City County District Type District Size  School Type  ...  \\\n",
       "0      Payson  Adams          UNIT        MEDIUM  HIGH SCHOOL  ...   \n",
       "1     Liberty  Adams          UNIT        MEDIUM  HIGH SCHOOL  ...   \n",
       "2  Camp Point  Adams          UNIT        MEDIUM  HIGH SCHOOL  ...   \n",
       "3      Mendon  Adams          UNIT        MEDIUM  HIGH SCHOOL  ...   \n",
       "4      Quincy  Adams          UNIT         LARGE  HIGH SCHOOL  ...   \n",
       "\n",
       "   American Indian and Alaska Native alone (estimate)  \\\n",
       "0                                               17.0    \n",
       "1                                               45.0    \n",
       "2                                                0.0    \n",
       "3                                                5.0    \n",
       "4                                               28.0    \n",
       "\n",
       "   American Indian and Alaska Native alone (percentage)  \\\n",
       "0                                                0.3      \n",
       "1                                                1.6      \n",
       "2                                                0.0      \n",
       "3                                                0.1      \n",
       "4                                                0.4      \n",
       "\n",
       "   Asian alone (estimate)  Asian alone (percentage)  \\\n",
       "0                     0.0                       0.0   \n",
       "1                     0.0                       0.0   \n",
       "2                    24.0                       1.1   \n",
       "3                   152.0                       2.6   \n",
       "4                   101.0                       1.3   \n",
       "\n",
       "   Native Hawaiian and Other Pacific Islander alone (estimate)  \\\n",
       "0                                                0.0             \n",
       "1                                                0.0             \n",
       "2                                                0.0             \n",
       "3                                                9.0             \n",
       "4                                                0.0             \n",
       "\n",
       "   Native Hawaiian and Other Pacific Islander alone (percentage)  \\\n",
       "0                                                0.0               \n",
       "1                                                0.0               \n",
       "2                                                0.0               \n",
       "3                                                0.2               \n",
       "4                                                0.0               \n",
       "\n",
       "  Some other race alone (estimate) Some other race alone (percentage)  \\\n",
       "0                              0.0                                0.0   \n",
       "1                              0.0                                0.0   \n",
       "2                              0.0                                0.0   \n",
       "3                              0.0                                0.0   \n",
       "4                              0.0                                0.0   \n",
       "\n",
       "  Two or more races alone (estimate) Two or more races alone (percentage)  \n",
       "0                               67.0                                  1.1  \n",
       "1                                1.0                                  0.0  \n",
       "2                                5.0                                  0.2  \n",
       "3                               93.0                                  1.6  \n",
       "4                              163.0                                  2.0  \n",
       "\n",
       "[5 rows x 77 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = \"Illinois\"  # State\n",
    "input_ed_csv = \"/home/mark/Documents/Erdos/Proj/math_ed_project/data/IL20/IL20_ed_data.csv\" # Input education data file\n",
    "input_census_csv = \"/home/mark/Documents/Erdos/Proj/math_ed_project/data/census_data/IL/20/IL20_census_data.csv\" #Input census data file\n",
    "input_county_csv = \"~/Documents/Erdos/Proj/math_ed_project/data/county_codes.csv\" #Path to County Codes\n",
    "output_csv = \"/home/mark/Documents/Erdos/Proj/math_ed_project/data/IL20/IL20_Combined_Census_Education.csv\"  # Output file\n",
    "\n",
    "\n",
    "def build_csv(input_ed_csv,input_census_csv,input_county_csv,state,output_csv):\n",
    "    #Takes input_ed_csv, input_census_csv, and input_county_csv, and combines into single csv.\n",
    "    # *_csv arguments are all filepaths to csv file.\n",
    "    # state is a string specifying which state this applies to.\n",
    "   \n",
    "\n",
    "    #Import and format county code data\n",
    "    countydf=pd.read_csv(input_county_csv)\n",
    "    countydf[\"state_name\"] = countydf[\"state_name\"].str.strip()\n",
    "    countydf[\"county_name\"] = countydf[\"county_name\"].str.strip()\n",
    "    countydf[\"county_code\"] = countydf[\"county_code\"].astype(str)\n",
    "\n",
    "    # Read ed_CSV into Pandas DataFrame\n",
    "    ext = input_ed_csv.split('.')[-1] #Get the file type, since they're not all csv files.\n",
    "    if ext == \"csv\":\n",
    "        df = pd.read_csv(input_ed_csv)\n",
    "    else:\n",
    "        df = df = pd.read_excel(input_ed_csv)\n",
    "\n",
    "    #Can't work with entries with no school name\n",
    "    df = df.dropna(subset=[\"School Name\"])\n",
    "\n",
    "\n",
    "    #Read census_CSV into data frame. Make unique ID a string, which ends up being convenient.\n",
    "    dfcensus = pd.read_csv(input_census_csv)\n",
    "    dfcensus[\"unique_id\"]=dfcensus[\"unique_id\"].astype(str)\n",
    "\n",
    "    #Fetch Geo data using google maps API\n",
    "  # Apply the function to get location details and add the resulting columns to the DataFrame\n",
    "    df[\"state_name\"] = state\n",
    "    df[[\"latitude\", \"longitude\", \"address\", \"zip_code\", \"county_name\", \"city_name\"]] = df.apply(get_location_details_google, axis=1)\n",
    "\n",
    "    #For whatever reason google doesn't succeed at grabbing all the county names at first pass.\n",
    "    fetch_missing_county_names(df,gmaps,state)\n",
    "    \n",
    "    #Load County ID data into df\n",
    "    df = df.merge(countydf, on=[\"state_name\", \"county_name\"], how=\"left\")\n",
    "\n",
    "\n",
    "    #First do batch census geoprocessing wherever possible\n",
    "    df = batch_census_tract(df)\n",
    "\n",
    "\n",
    "    #only then do individual census geoprocessing, on the stragglers\n",
    "    df = add_missing_census_tracts(df)\n",
    "\n",
    "      \n",
    "    df[\"unique_id\"] = df[\"county_code\"].astype(str) + df[\"Tract\"].astype(str)\n",
    "\n",
    "\n",
    "    df = df.merge(dfcensus, on=\"unique_id\", how=\"left\")\n",
    "\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "df = build_csv(input_ed_csv,input_census_csv,input_county_csv,state,output_csv)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finally, check that there weren't too many errors in the merging. If not, write out to csv.\n",
    "if (df[df[\"American Indian and Alaska Native alone (estimate)\"].isna()].shape)[0] <10:\n",
    "    df = df.dropna(subset = [\"American Indian and Alaska Native alone (estimate)\"])\n",
    "    df.to_csv(output_csv, index=False)\n",
    "else:\n",
    "    print(\"false\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
